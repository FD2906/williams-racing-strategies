{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3914cd35",
   "metadata": {},
   "source": [
    "# KPI 2.1 - Constructor Pit Stops - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1900e",
   "metadata": {},
   "source": [
    "This notebook focuses on feature engineering to respond to 'Strategic Question 2' from the project's research stage. \n",
    "\n",
    "**Question 2:** \n",
    ">*“To what extent did Williams benefit from safety car or virtual safety car periods in pit strategy or position gains during the 2015-2019 F1 seasons, and how can these opportunities be better exploited?”*\n",
    "\n",
    "**KPI 2:**\n",
    ">*2.1 Pit Stop Efficiency Score: Average pit stop duration and variance, benchmarked against midfield teams (e.g. % sec compared to the mean and std. duration of others)*\n",
    "\n",
    "(This can be done using the Kaggle dataset)\n",
    "\n",
    ">*2.2 Safety Car Opportunity Capture: Positions gained/lost during safety car or VSC periods.*\n",
    "\n",
    "(This can only be done with Fast-F1)\n",
    "\n",
    "**Hypothesis 2:**\n",
    ">*Williams gained fewer positions during safety car or VSC periods than midfield rivals between 2015-2019, due in part to slower pit stops and reduced ability to defend or consolidate gained positions after race restarts.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d43dba",
   "metadata": {},
   "source": [
    "**Steps required - 2.1:**\n",
    "Goal: quantify how Williams and rivals performed in pit stops compared to *fastest* and *most consistent* teams\n",
    "in any filtered scenario (e.g. season, GP, chaotic/non-chaotic/all race sessions)\n",
    "\n",
    "1. Define a function with the optional filters implemented as function parameters\n",
    "2. Group and aggregate the filtered data by `constructor_ref` and compute `mean`, `std`, and pit stop count. (Use robust indicators `median` and `MAD` (median absolute deviation) if outliers are present.)\n",
    "3. Benchmark by identifying and quantifying fastest team and most consistent team - smallest of mean/median and std/MAD\n",
    "4. Compute % over benchmark by adding new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61414268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('/Users/frankdong/Documents/Analytics Local/williams-racing-strategies/processed_data/constructor-pit-stops-validated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadbb66",
   "metadata": {},
   "source": [
    "## Steps 1 & 2: Define a function with filters, group and aggregate data by computing metrics like mean, std, median, MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed159d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pit_stats(df: pd.DataFrame,\n",
    "                    gp_year: int | list[int], # mandatory filter - must specify which year\n",
    "                    gp_name: str | list[str] = None, # optional filter - by GP name\n",
    "                    long_stop_flag: bool = None, # optional filter - by long stops or non-long stops only\n",
    "                    chaotic_race_flag: bool = None, # optional filter - by chaotic or non-chaotic sessions only\n",
    "                    verbose: bool = True): \n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    1. Filter by mandatory and optional filters from function parameters\n",
    "    2. Group and aggregate filtered data to compute mean, median, std, MAD, pit count\n",
    "    3. Return constructors by their mean, and std pit efficiency - ordered by mean desc. \n",
    "\n",
    "    Arguments:\n",
    "    df -- DataFrame containing constructor pit stop data\n",
    "    gp_year -- Single year or list of years to filter (**not optional**)\n",
    "    gp_name -- Single GP name or list of GP names to filter (optional)\n",
    "    long_stop_flag -- Filter to include or exclude long stops (optional)\n",
    "    chaotic_race_flag -- Filter for chaotic vs clean sessions (optional)\n",
    "    verbose -- If True, print filtering information (default: True)\n",
    "\n",
    "    Return:\n",
    "    A DataFrame with the mean and standard deviation of pit stops (in both ms and mm:ss:ms format), \n",
    "    along with lap counts, considering applied filters.\n",
    "    \"\"\"\n",
    "     \n",
    "    # 1. ---------- filter the data if parameters are provided ---------- \n",
    "    if gp_year is not None: \n",
    "        df = df[df['gp_year'].isin([gp_year] if isinstance(gp_year, int) else gp_year)]\n",
    "        if verbose: \n",
    "            print(f\"Filtering data for year(s): {gp_year}\")\n",
    "    if gp_name is not None: \n",
    "        df = df[df['gp_name'].isin([gp_name] if isinstance(gp_name, str) else gp_name)]\n",
    "        if verbose: \n",
    "            print(f\"Filtering data for GP name(s): {gp_name}\")\n",
    "    if long_stop_flag is not None: \n",
    "        df = df[df['long_stop_flag'].isin([long_stop_flag] if isinstance(long_stop_flag, bool) else long_stop_flag)]\n",
    "        if verbose:\n",
    "            print('Filtering data for long pit stops.' if long_stop_flag else 'Filtering data to exclude long pit stops.')\n",
    "    if chaotic_race_flag is not None: \n",
    "        df = df[df['chaotic_race_flag'].isin([chaotic_race_flag] if isinstance(chaotic_race_flag, bool) else chaotic_race_flag)]\n",
    "        if verbose:\n",
    "            print('Filtering data for chaotic race sessions.' if chaotic_race_flag else 'Filtering data to exclude chaotic race sessions.')\n",
    "    \n",
    "    # 2. ---------- group and calculate statistical metrics ----------\n",
    "    \n",
    "    \"\"\"\n",
    "    as outliers have been left in, we are using median and MAD along with mean and std\n",
    "    benchmarking in the next function will be applied on median and MAD found here\n",
    "    \"\"\"\n",
    "    pit_stats = df.groupby('constructor_ref').agg(\n",
    "        median_s = ('pit_duration_ms', lambda x: round(x.median() / 1000, 3)),\n",
    "        mean_s = ('pit_duration_ms', lambda x: round(x.mean() / 1000, 3)),\n",
    "        mad_s = ('pit_duration_ms', lambda x: round(np.median(np.abs(x - np.median(x))) / 1000, 3)),\n",
    "        std_s = ('pit_duration_ms', lambda x: round(x.std() / 1000, 3)),\n",
    "        n_pitstops = ('pit_duration_ms', 'count') \n",
    "    )\n",
    "\n",
    "    return pit_stats.sort_values(by = ['median_s', 'mad_s', 'n_pitstops']) # return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357dec61",
   "metadata": {},
   "source": [
    "## Steps 3 & 4: - Benchmarking other teams against the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59881deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_against_best(df_agg: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    1. Filter by mandatory and optional filters from function parameters\n",
    "    2. Group and aggregate filtered data to compute mean, median, std, MAD, pit count\n",
    "    3. Return constructors by their mean, and std pit efficiency - ordered by mean desc. \n",
    "\n",
    "    Arguments:\n",
    "    df.agg -- Aggregated dataframe containing pit stop statistics\n",
    "    verbose -- boolean value controlling if additional results are printed, e.g. winning teams\n",
    "\n",
    "    Return:\n",
    "    A DataFrame identifying the baseline constructor in both median and MAD pit stop times\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. -------- Benchmark teams against the fastest and most consistent values --------\n",
    "    df_agg = df_agg.reset_index()\n",
    "    benchmark_stats = df_agg[['constructor_ref', 'median_s', 'mad_s', 'n_pitstops']].copy() \n",
    "\n",
    "    fastest = benchmark_stats['median_s'].min() # find fastest \n",
    "    most_consistent = benchmark_stats['mad_s'].min() # find most consistent\n",
    "\n",
    "    benchmark_stats['slower_by_s'] = (\n",
    "        benchmark_stats['median_s'] - fastest\n",
    "    )\n",
    "    \n",
    "    benchmark_stats['percent_slower'] = (\n",
    "        round(((benchmark_stats['median_s'] - fastest) / fastest) * 100, 2)\n",
    "    )\n",
    "\n",
    "    benchmark_stats['percent_less_consistent'] = (\n",
    "        round(((benchmark_stats['mad_s'] - most_consistent) / most_consistent) * 100, 2)\n",
    "    )\n",
    "\n",
    "    # reorder columns\n",
    "    benchmark_stats = benchmark_stats[['constructor_ref', 'median_s', 'slower_by_s', 'percent_slower', 'mad_s', 'percent_less_consistent', 'n_pitstops']] \n",
    "\n",
    "    # 2. ---------- Find fastest and most consistent teams ----------\n",
    "\n",
    "    # reference column values\n",
    "    fastest_team_ref = benchmark_stats.loc[benchmark_stats['percent_slower'] == 0, 'constructor_ref'].values[0]\n",
    "    most_consistent_team_ref = benchmark_stats.loc[benchmark_stats['percent_less_consistent'] == 0, 'constructor_ref'].values[0]\n",
    "\n",
    "    # find the actual names, based on the global dataframe - if verbose True\n",
    "    if verbose:\n",
    "        fastest_team = df.loc[df['constructor_ref'] == fastest_team_ref, 'constructor'].unique()[0] \n",
    "        most_consistent_team = df.loc[df['constructor_ref'] == most_consistent_team_ref, 'constructor'].unique()[0]\n",
    "\n",
    "        print(f\"\\nFastest team (median): {fastest_team}\")\n",
    "        print(f\"Most consistent team (MAD): {most_consistent_team}\")\n",
    "\n",
    "    # 3. Return dataframe\n",
    "\n",
    "    return benchmark_stats.sort_values(by = ['percent_slower', 'percent_less_consistent']).set_index('constructor_ref')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2ad30",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa0dc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Test 1: Filtered pit stop data - 2015 to 2019, exclude long stops and chaotic races. ----- \n",
      "\n",
      "                 median_s  mean_s  mad_s  std_s  n_pitstops\n",
      "constructor_ref                                            \n",
      "racing_point       23.334  25.602  1.392  4.548          32\n",
      "williams           23.861  24.905  1.812  4.323         187\n",
      "haas               23.932  25.301  1.492  4.518         126\n",
      "renault            24.015  25.132  1.792  4.888         120\n",
      "force_india        24.043  25.151  1.498  4.137         135\n",
      "\n",
      "Fastest team (median): Racing Point\n",
      "Most consistent team (MAD): Racing Point\n",
      "                 median_s  slower_by_s  percent_slower  mad_s  \\\n",
      "constructor_ref                                                 \n",
      "racing_point       23.334        0.000            0.00  1.392   \n",
      "williams           23.861        0.527            2.26  1.812   \n",
      "haas               23.932        0.598            2.56  1.492   \n",
      "renault            24.015        0.681            2.92  1.792   \n",
      "force_india        24.043        0.709            3.04  1.498   \n",
      "\n",
      "                 percent_less_consistent  n_pitstops  \n",
      "constructor_ref                                       \n",
      "racing_point                        0.00          32  \n",
      "williams                           30.17         187  \n",
      "haas                                7.18         126  \n",
      "renault                            28.74         120  \n",
      "force_india                         7.61         135  \n"
     ]
    }
   ],
   "source": [
    "print(\"----- Test 1: Filtered pit stop data - 2015 to 2019, exclude long stops and chaotic races. ----- \\n\")\n",
    "test1 = get_pit_stats(df, [2015, 2016, 2017, 2018, 2019], long_stop_flag = False, chaotic_race_flag = False, verbose = False) \n",
    "print(test1)\n",
    "test1_benchmarking = benchmark_against_best(test1)\n",
    "print(test1_benchmarking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e371c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Test 2: Non-filtered pit stop data - 2015 to 2019. ----------------------\n",
      "\n",
      "                 median_s  mean_s  mad_s    std_s  n_pitstops\n",
      "constructor_ref                                              \n",
      "racing_point       23.334  25.602  1.392    4.548          32\n",
      "williams           23.927  66.986  2.071  255.129         211\n",
      "haas               24.219  64.780  1.792  238.841         137\n",
      "renault            24.269  58.328  1.964  226.463         135\n",
      "force_india        24.282  83.322  1.842  299.102         152\n",
      "\n",
      "Fastest team (median): Racing Point\n",
      "Most consistent team (MAD): Racing Point\n",
      "                 median_s  slower_by_s  percent_slower  mad_s  \\\n",
      "constructor_ref                                                 \n",
      "racing_point       23.334        0.000            0.00  1.392   \n",
      "williams           23.927        0.593            2.54  2.071   \n",
      "haas               24.219        0.885            3.79  1.792   \n",
      "renault            24.269        0.935            4.01  1.964   \n",
      "force_india        24.282        0.948            4.06  1.842   \n",
      "\n",
      "                 percent_less_consistent  n_pitstops  \n",
      "constructor_ref                                       \n",
      "racing_point                        0.00          32  \n",
      "williams                           48.78         211  \n",
      "haas                               28.74         137  \n",
      "renault                            41.09         135  \n",
      "force_india                        32.33         152  \n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------- Test 2: Non-filtered pit stop data - 2015 to 2019. ----------------------\\n\")\n",
    "test2 = get_pit_stats(df, [2015, 2016, 2017, 2018, 2019], verbose = False) # all results \n",
    "print(test2)\n",
    "test2_benchmarking = benchmark_against_best(test2)\n",
    "print(test2_benchmarking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
